ğŸ“Œ Silent Signals â€“ Early Intent & Posture Detection System

Silent Signals is a real-time computer vision project that detects a personâ€™s posture (such as Sitting or Standing) and identifies early intent cues before a full action occurs.
The system uses body landmarks and motion analysis to infer human behavior without requiring speech or wearable devices.

ğŸ¯ Project Objective

The goal of Silent Signals is to:
Detect human posture in real time
Identify early intent (possible action starting) using subtle movements
Provide a foundation for non-verbal humanâ€“computer interaction
This project demonstrates how intent can be predicted before a complete action, which is useful in accessibility, surveillance, healthcare, and smart environments.

ğŸ§  Key Features

ğŸ“· Real-time webcam-based detection
ğŸ§ Posture classification:
Sitting
Standing
âš¡ Intent detection states:
NO ACTION
POSSIBLE INTENT
ACTION STARTING (with confidence score)
ğŸ§  ML-based intent classification using landmark movement
ğŸš« No wearable sensors required

ğŸ› ï¸ Tech Stack
Python
OpenCV â€“ video capture & visualization
MediaPipe â€“ pose landmark extraction
TensorFlow / Keras â€“ intent classification model
NumPy â€“ numerical processing

ğŸ§ª How It Works (High Level)

Webcam captures live video
MediaPipe extracts body pose landmarks
Posture is determined using joint positions
Landmark movement over time is analyzed
ML model predicts intent state:
No Action
Possible Intent
Action Starting
Output is displayed in real time

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Create virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run the program
python silent_signals.py

4ï¸âƒ£ Controls
Press q to quit the application

ğŸ“Š Sample Output
POSTURE: SITTING
INTENT: NO ACTION

POSTURE: STANDING
INTENT: POSSIBLE INTENT

POSTURE: STANDING
INTENT: ACTION STARTING
Confidence: 0.94

ğŸš€ Applications

Accessibility systems
Smart surveillance
Humanâ€“computer interaction
Assistive technology
Behavioral analysis

ğŸ“Œ Limitations

Intent prediction is probabilistic
Requires visible upper body
Performance depends on lighting and camera position

ğŸ”® Future Enhancements

Gesture-specific intent detection (e.g., hand raise, waving)
Multi-person support
Improved early prediction accuracy
Deployment as a desktop or mobile app

ğŸ‘©â€ğŸ’» Author

Gayathri
Internship Project â€“ Silent Signals
GitHub: https://github.com/Gayathri21-Git

ğŸ“œ License

This project is licensed under the MIT License.
